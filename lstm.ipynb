{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deea9a00-135f-46ce-82be-763c86ca0f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences: (49043, 3, 18) labels: [45806  3237]\n",
      "Test  sequences: (12452, 3, 18) labels: [11677   775]\n",
      "Balanced train: (6474, 3, 18) labels: [3237 3237]\n",
      "Epoch 1/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - accuracy: 0.5080 - loss: 0.6930\n",
      "Epoch 2/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5318 - loss: 0.6913\n",
      "Epoch 3/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5531 - loss: 0.6898\n",
      "Epoch 4/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5650 - loss: 0.6883\n",
      "Epoch 5/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5817 - loss: 0.6869\n",
      "Epoch 6/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5901 - loss: 0.6855\n",
      "Epoch 7/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5941 - loss: 0.6840\n",
      "Epoch 8/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5996 - loss: 0.6824\n",
      "Epoch 9/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6052 - loss: 0.6808\n",
      "Epoch 10/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6109 - loss: 0.6789\n",
      "Epoch 11/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6132 - loss: 0.6770\n",
      "Epoch 12/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6158 - loss: 0.6751\n",
      "Epoch 13/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6182 - loss: 0.6732\n",
      "Epoch 14/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6180 - loss: 0.6713\n",
      "Epoch 15/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6191 - loss: 0.6694\n",
      "Epoch 16/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6191 - loss: 0.6676\n",
      "Epoch 17/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6225 - loss: 0.6658\n",
      "Epoch 18/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6219 - loss: 0.6642\n",
      "Epoch 19/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6219 - loss: 0.6627\n",
      "Epoch 20/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6214 - loss: 0.6613\n",
      "Epoch 21/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6223 - loss: 0.6599\n",
      "Epoch 22/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6219 - loss: 0.6587\n",
      "Epoch 23/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6216 - loss: 0.6576\n",
      "Epoch 24/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6230 - loss: 0.6565\n",
      "Epoch 25/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6223 - loss: 0.6556\n",
      "Epoch 26/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6240 - loss: 0.6547\n",
      "Epoch 27/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6248 - loss: 0.6540\n",
      "Epoch 28/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6243 - loss: 0.6533\n",
      "Epoch 29/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6253 - loss: 0.6526\n",
      "Epoch 30/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6262 - loss: 0.6520\n",
      "Epoch 31/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6270 - loss: 0.6514\n",
      "Epoch 32/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6276 - loss: 0.6509\n",
      "Epoch 33/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6281 - loss: 0.6504\n",
      "Epoch 34/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6273 - loss: 0.6499\n",
      "Epoch 35/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6273 - loss: 0.6495\n",
      "Epoch 36/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6276 - loss: 0.6490\n",
      "Epoch 37/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6277 - loss: 0.6486\n",
      "Epoch 38/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6285 - loss: 0.6482\n",
      "Epoch 39/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6287 - loss: 0.6478\n",
      "Epoch 40/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6291 - loss: 0.6474\n",
      "Epoch 41/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6297 - loss: 0.6471\n",
      "Epoch 42/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6307 - loss: 0.6467\n",
      "Epoch 43/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6310 - loss: 0.6464\n",
      "Epoch 44/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6311 - loss: 0.6461\n",
      "Epoch 45/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6319 - loss: 0.6457\n",
      "Epoch 46/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6314 - loss: 0.6454\n",
      "Epoch 47/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6304 - loss: 0.6451\n",
      "Epoch 48/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6311 - loss: 0.6448\n",
      "Epoch 49/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6307 - loss: 0.6445\n",
      "Epoch 50/50\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6308 - loss: 0.6442\n",
      "\n",
      "Macro F1 on test set: 0.4787\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ======== REPRO ========\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ======== PARAMS ========\n",
    "WINDOW = 3\n",
    "EPOCHS = 50\n",
    "BALANCE = True\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "FEATURES = [f\"X{i}\" for i in range(1, 19)]\n",
    "\n",
    "# ======== LOAD ========\n",
    "train_path = \"dataset/train.csv\"\n",
    "test_path  = \"dataset/df1_matches.csv\"\n",
    "\n",
    "df_tr = pd.read_csv(train_path)\n",
    "df_te = pd.read_csv(test_path)\n",
    "\n",
    "# Clean\n",
    "for df in (df_tr, df_te):\n",
    "    for c in [\"Unnamed: 0\", \"Division\", \"MajorGroup\"]:\n",
    "        if c in df.columns:\n",
    "            df.drop(columns=c, inplace=True)\n",
    "    df.sort_values([\"company_name\", \"fyear\"], inplace=True)\n",
    "\n",
    "# Encode target\n",
    "label_map = {\"alive\": 0, \"failed\": 1}\n",
    "df_tr[\"status\"] = df_tr[\"status_label\"].map(label_map)\n",
    "df_te[\"status\"] = df_te[\"status_label\"].map(label_map)\n",
    "\n",
    "# ======== SEQUENCES ========\n",
    "def make_sequences(df, window, features, group_col=\"company_name\", time_col=\"fyear\", target_col=\"status\"):\n",
    "    Xs, ys = [], []\n",
    "    for _, g in df.groupby(group_col):\n",
    "        g = g.sort_values(time_col)\n",
    "        if len(g) >= window:\n",
    "            for i in range(len(g) - window + 1):\n",
    "                seq = g.iloc[i:i+window]\n",
    "                Xs.append(seq[features].values)   # (W, F)\n",
    "                ys.append(seq[target_col].values[-1])\n",
    "    return np.array(Xs, dtype=np.float32), np.array(ys, dtype=np.int64)\n",
    "\n",
    "X_tr, y_tr = make_sequences(df_tr, WINDOW, FEATURES)\n",
    "X_te, y_te = make_sequences(df_te, WINDOW, FEATURES)\n",
    "\n",
    "print(\"Train sequences:\", X_tr.shape, \"labels:\", np.bincount(y_tr))\n",
    "print(\"Test  sequences:\", X_te.shape, \"labels:\", np.bincount(y_te))\n",
    "\n",
    "# ======== BALANCE (undersample) ========\n",
    "if BALANCE and len(np.unique(y_tr)) == 2:\n",
    "    idx0 = np.where(y_tr == 0)[0]\n",
    "    idx1 = np.where(y_tr == 1)[0]\n",
    "    n = min(len(idx0), len(idx1))\n",
    "    sel = np.concatenate([\n",
    "        np.random.choice(idx0, n, replace=False),\n",
    "        np.random.choice(idx1, n, replace=False),\n",
    "    ])\n",
    "    np.random.shuffle(sel)\n",
    "    X_tr, y_tr = X_tr[sel], y_tr[sel]\n",
    "    print(\"Balanced train:\", X_tr.shape, \"labels:\", np.bincount(y_tr))\n",
    "\n",
    "# ======== NORMALIZE using TRAIN stats ========\n",
    "mean = X_tr.mean(axis=(0,1))\n",
    "std  = X_tr.std(axis=(0,1))\n",
    "std[std == 0] = 1.0\n",
    "X_tr = (X_tr - mean) / std\n",
    "X_te = (X_te - mean) / std\n",
    "\n",
    "# ======== MODEL (multi-head per feature, like your reference) ========\n",
    "inputs, heads = [], []\n",
    "for _ in FEATURES:\n",
    "    inp = tf.keras.Input(shape=(WINDOW, 1))\n",
    "    h = LSTM(WINDOW)(inp)      # small units to mirror reference\n",
    "    inputs.append(inp)\n",
    "    heads.append(h)\n",
    "\n",
    "merged = Concatenate()(heads)\n",
    "dense1 = Dense(20, activation='relu')(merged)\n",
    "out = Dense(2, activation='softmax')(dense1)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Prepare split inputs\n",
    "Xtr_split = [X_tr[:,:,i].reshape(-1, WINDOW, 1) for i in range(X_tr.shape[2])]\n",
    "Xte_split = [X_te[:,:,i].reshape(-1, WINDOW, 1) for i in range(X_te.shape[2])]\n",
    "\n",
    "# ======== TRAIN on FULL TRAINING DATA (no val split) ========\n",
    "model.fit(\n",
    "    Xtr_split, to_categorical(y_tr, num_classes=2),\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, shuffle=True\n",
    ")\n",
    "\n",
    "# ======== EVAL on TEST ========\n",
    "y_prob = model.predict(Xte_split, verbose=0)[:, 1]\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "macro_f1 = f1_score(y_te, y_pred, average='macro')\n",
    "print(f\"\\nMacro F1 on test set: {macro_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26181a1-f5ed-45e3-9e3a-570d56f09416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62789, 24)\n",
      "Index(['Unnamed: 0', 'company_name', 'fyear', 'status_label', 'X1', 'X2', 'X3',\n",
      "       'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14',\n",
      "       'X15', 'X16', 'X17', 'X18', 'Division', 'MajorGroup'],\n",
      "      dtype='object')\n",
      "   Unnamed: 0 company_name   fyear status_label        X1          X2  \\\n",
      "0           0          C_1  1999.0        alive  511267.0  740998.000   \n",
      "1           1          C_1  2000.0        alive  485856.0     701.854   \n",
      "2           2          C_1  2001.0        alive  436656.0  710199.000   \n",
      "3           3          C_1  2002.0        alive  396412.0     686.621   \n",
      "4           4          C_1  2003.0        alive  432204.0     709.292   \n",
      "\n",
      "         X3        X4        X5        X6  ...        X11         X12  \\\n",
      "0  833107.0  180447.0  18373.00  70658.00  ...     35.163  201026.000   \n",
      "1  713811.0  179987.0  18577.00     45.79  ...  18531.000  204065.000   \n",
      "2  526477.0  217699.0  22496.00   4711.00  ...    -58.939     139.603   \n",
      "3  496747.0  164658.0  27172.00   3573.00  ...    -12.410  124106.000   \n",
      "4  523302.0  248666.0     26.68  20811.00  ...   3504.000  131884.000   \n",
      "\n",
      "          X13          X14       X15       X16          X17       X18  \\\n",
      "0     128.348  1024333.000  372.7519  401483.0  1024333.000  935302.0   \n",
      "1  115187.000   874255.000  377.1180  361642.0   874255.000  809888.0   \n",
      "2   77528.000   638721.000  364.5928  399964.0   638721.000  611514.0   \n",
      "3   66322.000   606337.000  143.3295  391633.0   606337.000  575592.0   \n",
      "4  104661.000      651.958  308.9071  407608.0      651.958  604467.0   \n",
      "\n",
      "   Division  MajorGroup  \n",
      "0         D          37  \n",
      "1         D          37  \n",
      "2         D          37  \n",
      "3         D          37  \n",
      "4         D          37  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset/train.csv\")\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a449937-95ef-4fca-bff7-ac72db16dd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15893, 23)\n",
      "Index(['company_name', 'fyear', 'status_label', 'X1', 'X2', 'X3', 'X4', 'X5',\n",
      "       'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16',\n",
      "       'X17', 'X18', 'Division', 'MajorGroup'],\n",
      "      dtype='object')\n",
      "  company_name   fyear status_label        X1        X2       X3      X4  \\\n",
      "0          C_3  1999.0        alive  9757.000  13986.00  19796.0  5974.0   \n",
      "1          C_3  2000.0        alive     7.884  11608.00  16506.0  4875.0   \n",
      "2          C_3  2001.0        alive  6494.000   8635.00     15.7  3873.0   \n",
      "3          C_3  2002.0        alive  5938.000      7.85  12919.0  2546.0   \n",
      "4          C_3  2004.0        alive  5807.000   6245.00  12018.0   222.0   \n",
      "\n",
      "        X5        X6      X7  ...       X11     X12     X13       X14  \\\n",
      "0  667.000  -932.000  -265.0  ... -2207.000 -6375.0  3924.0     29.37   \n",
      "1    0.700    -0.028   672.0  ...    -0.808 -7184.0  3244.0  25367.00   \n",
      "2    0.761    -0.380   381.0  ...    -1.738 -8922.0  2677.0  24051.00   \n",
      "3  355.000   356.000   711.0  ...    84.000 -8816.0  2465.0  20087.00   \n",
      "4    0.160  1454.000  1614.0  ...  1345.000 -8974.0  2504.0  19833.00   \n",
      "\n",
      "       X15       X16       X17       X18  Division  MajorGroup  \n",
      "0   3.2449     8.778     29.37  29635.00         D          38  \n",
      "1   4.5428  7153.000  25367.00  24695.00         D          38  \n",
      "2   2.9667     5.918  24051.00     23.67         D          38  \n",
      "3   1.5761  5027.000  20087.00  19376.00         D          38  \n",
      "4  13.9065     3.580  19833.00  18219.00         D          38  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset/df1_matches.csv\")\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2716da5-2695-4311-9fa1-5f8e153e88e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
