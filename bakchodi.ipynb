{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97dbd706-70ad-4088-ac57-db40d77643f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight = 13.94\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Load\n",
    "train = pd.read_csv(\"dataset/train.csv\")\n",
    "test = pd.read_csv(\"dataset/df1_matches.csv\")\n",
    "\n",
    "train.drop(columns=[\"Unnamed: 0\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Encode labels\n",
    "train[\"status_label\"] = train[\"status_label\"].map({'alive': 0, 'failed': 1})\n",
    "test[\"status_label\"] = test[\"status_label\"].map({'alive': 0, 'failed': 1})\n",
    "\n",
    "# Encode categories\n",
    "le_div = LabelEncoder()\n",
    "le_major = LabelEncoder()\n",
    "train[\"Division\"] = le_div.fit_transform(train[\"Division\"])\n",
    "test[\"Division\"] = le_div.transform(test[\"Division\"])\n",
    "train[\"MajorGroup\"] = le_major.fit_transform(train[\"MajorGroup\"])\n",
    "test[\"MajorGroup\"] = le_major.transform(test[\"MajorGroup\"])\n",
    "\n",
    "# Feature / target split\n",
    "X_train = train.drop(columns=[\"company_name\", \"fyear\", \"status_label\"])\n",
    "y_train = train[\"status_label\"]\n",
    "X_test  = test.drop(columns=[\"company_name\", \"fyear\", \"status_label\"])\n",
    "y_test  = test[\"status_label\"]\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# Ratio of classes for imbalance weighting\n",
    "scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "print(\"scale_pos_weight =\", round(scale_pos_weight,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14af8edf-68d7-4c17-9894-a44cace0da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost ===\n",
      "Macro F1: 0.5628426474064498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9426    0.9665    0.9544     14876\n",
      "           1     0.2215    0.1396    0.1713      1017\n",
      "\n",
      "    accuracy                         0.9135     15893\n",
      "   macro avg     0.5821    0.5530    0.5628     15893\n",
      "weighted avg     0.8965    0.9135    0.9043     15893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=1200,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(\"\\n=== XGBoost ===\")\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred_xgb, average='macro'))\n",
    "print(classification_report(y_test, y_pred_xgb, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f71fc409-dc3b-42b5-b1a9-8310fc02f213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual class weights: 1.0 20.908636688079945\n",
      "0:\tlearn: 0.7557554\ttest: 0.7210278\tbest: 0.7210278 (0)\ttotal: 53.2ms\tremaining: 1m 46s\n",
      "200:\tlearn: 0.8533557\ttest: 0.7118600\tbest: 0.7383829 (38)\ttotal: 9.72s\tremaining: 1m 27s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7383829248\n",
      "bestIteration = 38\n",
      "\n",
      "Shrink model to first 39 iterations.\n",
      "\n",
      "Best threshold = 0.60\n",
      "Macro F1 = 0.5565755204195643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9503    0.8684    0.9075     14876\n",
      "           1     0.1483    0.3353    0.2057      1017\n",
      "\n",
      "    accuracy                         0.8343     15893\n",
      "   macro avg     0.5493    0.6018    0.5566     15893\n",
      "weighted avg     0.8990    0.8343    0.8626     15893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Compute manual class weights\n",
    "neg, pos = np.bincount(y_train)\n",
    "weight_for_0 = 1.0\n",
    "weight_for_1 = (neg / pos) * 1.5  # amplify a bit beyond balance\n",
    "\n",
    "print(\"Manual class weights:\", weight_for_0, weight_for_1)\n",
    "\n",
    "train_pool = Pool(X_train, y_train)\n",
    "test_pool  = Pool(X_test, y_test)\n",
    "\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.02,\n",
    "    depth=10,\n",
    "    l2_leaf_reg=5,\n",
    "    border_count=128,\n",
    "    class_weights=[weight_for_0, weight_for_1],\n",
    "    eval_metric='F1',\n",
    "    random_seed=42,\n",
    "    verbose=200,\n",
    "    early_stopping_rounds=200,\n",
    ")\n",
    "\n",
    "cat.fit(train_pool, eval_set=test_pool, use_best_model=True)\n",
    "\n",
    "# Predict with tuned threshold\n",
    "proba = cat.predict_proba(X_test)[:, 1]\n",
    "\n",
    "best_f1, best_thr = 0, 0.5\n",
    "for thr in np.linspace(0.1, 0.9, 17):\n",
    "    f1 = f1_score(y_test, (proba > thr).astype(int), average='macro')\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_thr = f1, thr\n",
    "\n",
    "y_pred_opt = (proba > best_thr).astype(int)\n",
    "print(f\"\\nBest threshold = {best_thr:.2f}\")\n",
    "print(\"Macro F1 =\", best_f1)\n",
    "print(classification_report(y_test, y_pred_opt, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758185e2-7cfd-4deb-a878-9f38bd5d721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution (train): Counter({0: 58586, 1: 4203}), class_weights=[1.0, 13.939091125386629]\n",
      "\n",
      "===== Fold 1 =====\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Bankruptcy Classification â€” Clean Final Script\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "from collections import Counter\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load\n",
    "# -----------------------------\n",
    "train = pd.read_csv(\"dataset/train.csv\")\n",
    "test  = pd.read_csv(\"dataset/df1_matches.csv\")\n",
    "\n",
    "# Align label column name if needed (your text shows both status_label and Bankruptcy_Status)\n",
    "LABEL_COL = \"status_label\" if \"status_label\" in train.columns else \"Bankruptcy_Status\"\n",
    "\n",
    "# Map labels to {alive:0, failed:1}\n",
    "label_map = {\"alive\": 0, \"failed\": 1}\n",
    "train[LABEL_COL] = train[LABEL_COL].map(label_map)\n",
    "test[LABEL_COL]  = test[LABEL_COL].map(label_map)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Basic cleaning\n",
    "# -----------------------------\n",
    "# Ensure Division is string for CatBoost categorical\n",
    "if \"Division\" in train.columns:\n",
    "    train[\"Division\"] = train[\"Division\"].astype(str)\n",
    "    test[\"Division\"]  = test[\"Division\"].astype(str)\n",
    "\n",
    "# Drop obvious non-features later; keep for grouping right now\n",
    "DROP_COLS = [\"Unnamed: 0\", \"company_name\", \"fyear\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Feature engineering\n",
    "# -----------------------------\n",
    "def add_core_ratios(df):\n",
    "    eps = 1e-6\n",
    "\n",
    "    # Readable aliases\n",
    "    CA  = df[\"X1\"]   # Current Assets\n",
    "    COGS= df[\"X2\"]   # Cost of Goods Sold\n",
    "    DA  = df[\"X3\"]   # Depreciation & Amortization\n",
    "    EBITDA = df[\"X4\"]\n",
    "    INV = df[\"X5\"]\n",
    "    NI  = df[\"X6\"]   # Net Income\n",
    "    AR  = df[\"X7\"]   # Total Receivables\n",
    "    MV  = df[\"X8\"]   # Market Value\n",
    "    SALES = df[\"X9\"] # Net Sales\n",
    "    TA  = df[\"X10\"]  # Total Assets\n",
    "    LTD = df[\"X11\"]  # Total Long Term Debt\n",
    "    EBIT = df[\"X12\"]\n",
    "    GP  = df[\"X13\"]  # Gross Profit\n",
    "    TCL = df[\"X14\"]  # Total Current Liabilities\n",
    "    RE  = df[\"X15\"]  # Retained Earnings\n",
    "    TR  = df[\"X16\"]  # Total Revenue\n",
    "    TL  = df[\"X17\"]  # Total Liabilities\n",
    "    TOE = df[\"X18\"]  # Total Operating Expenses\n",
    "\n",
    "    # Liquidity\n",
    "    df[\"Current_Ratio\"] = CA / (TCL + eps)\n",
    "    df[\"Quick_Ratio\"]   = (CA - INV) / (TCL + eps)\n",
    "    df[\"Working_Capital\"] = CA - TCL\n",
    "    df[\"WC_to_Assets\"]  = (df[\"Working_Capital\"]) / (TA + eps)\n",
    "\n",
    "    # Leverage\n",
    "    df[\"Debt_to_Assets\"] = TL / (TA + eps)\n",
    "    df[\"Debt_to_Equity\"] = TL / (np.maximum(TA - TL, 0) + eps)\n",
    "    df[\"LTD_to_Assets\"]  = LTD / (TA + eps)\n",
    "\n",
    "    # Profitability\n",
    "    df[\"ROA\"] = NI / (TA + eps)\n",
    "    df[\"ROS\"] = NI / (SALES + eps)\n",
    "    df[\"Gross_Margin\"] = GP / (SALES + eps)\n",
    "    df[\"EBITDA_Margin\"] = EBITDA / (SALES + eps)\n",
    "\n",
    "    # Efficiency\n",
    "    df[\"Asset_Turnover\"] = SALES / (TA + eps)\n",
    "    df[\"Inventory_Turnover\"] = SALES / (INV + eps)\n",
    "    df[\"Receivables_Turnover\"] = SALES / (AR + eps)\n",
    "\n",
    "    # Size\n",
    "    df[\"Log_TA\"] = np.log(TA + eps)\n",
    "    df[\"Log_Sales\"] = np.log(SALES + eps)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_bankruptcy_scores(df):\n",
    "    eps = 1e-6\n",
    "    TA  = df[\"X10\"]\n",
    "    SALES = df[\"X9\"]\n",
    "    TL  = df[\"X17\"]\n",
    "    TCL = df[\"X14\"]\n",
    "    EBIT = df[\"X12\"]\n",
    "    RE   = df[\"X15\"]\n",
    "\n",
    "    # Altman Z (manufacturing version, using available proxies)\n",
    "    WC = df[\"Working_Capital\"]\n",
    "    df[\"Altman_Z\"] = (\n",
    "        1.2 * (WC / (TA + eps)) +\n",
    "        1.4 * (RE / (TA + eps)) +\n",
    "        3.3 * (EBIT / (TA + eps)) +\n",
    "        0.6 * (SALES / (TL + eps)) +\n",
    "        1.0 * (SALES / (TA + eps))\n",
    "    )\n",
    "\n",
    "    # Ohlson O-Score (partial; uses key drivers with available variables)\n",
    "    df[\"Ohlson_O\"] = (\n",
    "        -1.32\n",
    "        - 0.407 * np.log(TA + eps)\n",
    "        + 6.03 * (TCL / (TA + eps))\n",
    "        - 1.43 * (TL  / (TA + eps))\n",
    "        + 0.0757 * (TL / (SALES + eps))\n",
    "    )\n",
    "\n",
    "    # Shumway-like linear index\n",
    "    df[\"Shumway\"] = (\n",
    "        df[\"ROA\"] + df[\"Asset_Turnover\"] - df[\"Debt_to_Assets\"]\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_trend_features(df):\n",
    "    # Sort to compute within-company trends\n",
    "    if not {\"company_name\", \"fyear\"}.issubset(df.columns):\n",
    "        return df\n",
    "\n",
    "    df = df.sort_values([\"company_name\", \"fyear\"])\n",
    "    cols_to_trend = [\"X6\", \"X9\", \"X10\", \"Altman_Z\", \"Ohlson_O\", \"Shumway\", \"ROA\", \"Debt_to_Assets\"]\n",
    "    for c in cols_to_trend:\n",
    "        if c in df.columns:\n",
    "            df[f\"{c}_chg\"] = df.groupby(\"company_name\")[c].pct_change().replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_features(df):\n",
    "    df = add_core_ratios(df.copy())\n",
    "    df = add_bankruptcy_scores(df)\n",
    "    df = add_trend_features(df)\n",
    "    # Clean up numerical issues\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.kind in \"fc\":\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_fe = build_features(train)\n",
    "test_fe  = build_features(test)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Prepare matrices\n",
    "# -----------------------------\n",
    "# Keep company_name for grouping; drop from features later\n",
    "feature_cols = [c for c in train_fe.columns if c not in DROP_COLS + [LABEL_COL]]\n",
    "X = train_fe[feature_cols]\n",
    "y = train_fe[LABEL_COL].astype(int)\n",
    "X_test = test_fe[feature_cols]\n",
    "y_test = test_fe[LABEL_COL].astype(int)  # assuming available for evaluation\n",
    "\n",
    "# Identify categorical columns for CatBoost (Division only here)\n",
    "cat_features = []\n",
    "if \"Division\" in feature_cols:\n",
    "    cat_features.append(feature_cols.index(\"Division\"))  # index within X's columns\n",
    "\n",
    "# -----------------------------\n",
    "# 5) CV with GroupKFold (no company leakage)\n",
    "# -----------------------------\n",
    "groups = train[\"company_name\"]\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Class weights based on training distribution\n",
    "counter = Counter(y)\n",
    "neg, pos = counter[0], counter[1]\n",
    "class_weights = [1.0, max(1.0, neg / max(pos, 1))]  # e.g., ~14 if 58.5k/4.2k\n",
    "\n",
    "print(f\"Class distribution (train): {counter}, class_weights={class_weights}\")\n",
    "\n",
    "oof_pred = np.zeros(len(X))\n",
    "test_pred = np.zeros(len(X_test))\n",
    "\n",
    "fold = 1\n",
    "for tr_idx, va_idx in gkf.split(X, y, groups=groups):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"F1\",\n",
    "        depth=8,\n",
    "        iterations=2000,\n",
    "        learning_rate=0.02,\n",
    "        l2_leaf_reg=6.0,\n",
    "        random_seed=RANDOM_STATE + fold,\n",
    "        class_weights=class_weights,\n",
    "        verbose=False,\n",
    "        thread_count=-1\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=(X_va, y_va),\n",
    "        cat_features=cat_features,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "    oof_pred[va_idx] = model.predict_proba(X_va)[:, 1]\n",
    "    test_pred += model.predict_proba(X_test)[:, 1] / gkf.n_splits\n",
    "\n",
    "    # Quick per-fold check\n",
    "    best_f1, best_t = 0.0, 0.5\n",
    "    for t in np.linspace(0.05, 0.95, 91):\n",
    "        f1 = f1_score(y_va, (oof_pred[va_idx] > t).astype(int), average=\"macro\")\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    print(f\"Fold {fold} best macro-F1={best_f1:.4f} at threshold={best_t:.2f}\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Global threshold optimization on OOF\n",
    "# -----------------------------\n",
    "best_f1, best_t = 0.0, 0.5\n",
    "for t in np.linspace(0.05, 0.95, 181):\n",
    "    preds = (oof_pred > t).astype(int)\n",
    "    f1 = f1_score(y, preds, average=\"macro\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_t = f1, t\n",
    "\n",
    "print(\"\\n===== OOF Performance =====\")\n",
    "print(f\"Optimal threshold on OOF: {best_t:.3f}\")\n",
    "print(f\"OOF Macro F1: {best_f1:.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Final Test Evaluation\n",
    "# -----------------------------\n",
    "y_test_pred = (test_pred > best_t).astype(int)\n",
    "\n",
    "print(\"\\n===== Final Test Performance =====\")\n",
    "print(f\"Macro F1: {f1_score(y_test, y_test_pred, average='macro'):.6f}\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# -----------------------------\n",
    "# 8) (Optional) Inspect top features by CatBoost importance\n",
    "# -----------------------------\n",
    "# (Train a final model on full train to get importances)\n",
    "final_model = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"F1\",\n",
    "    depth=8,\n",
    "    iterations=2000,\n",
    "    learning_rate=0.02,\n",
    "    l2_leaf_reg=6.0,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    class_weights=class_weights,\n",
    "    verbose=False,\n",
    "    thread_count=-1\n",
    ")\n",
    "final_model.fit(X, y, cat_features=cat_features)\n",
    "\n",
    "importances = final_model.get_feature_importance(prettified=True)\n",
    "print(\"\\nTop 20 features by importance:\")\n",
    "print(importances.sort_values(\"Importances\", ascending=False).head(20))\n",
    "\n",
    "# If you want to save predictions:\n",
    "# pd.DataFrame({\"company_name\": test[\"company_name\"], \"pred_prob_failed\": test_pred, \"pred_label\": y_test_pred}).to_csv(\"predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc3bc9-3ea7-449a-9101-309b2dcceb50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
